<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>deep neural network programming exercises: layers Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">deep neural network programming exercises
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classlayers-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">layers Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Collaboration diagram for layers:</div>
<div class="dyncontent">
<div class="center"><img src="classlayers__coll__graph.png" border="0" usemap="#layers_coll__map" alt="Collaboration graph"/></div>
<map name="layers_coll__map" id="layers_coll__map">
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a4490dba95a8f233ca7e383fb3b20a822"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a4490dba95a8f233ca7e383fb3b20a822">layers</a> (int d, int length, float _keep_prob=1, bool _dropout=false, string _layer_type=&quot;None&quot;, string _act=&quot;None&quot;)</td></tr>
<tr class="separator:a4490dba95a8f233ca7e383fb3b20a822"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9b62e715089a55ab0116ffca0273b78"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ae9b62e715089a55ab0116ffca0273b78">layers</a> (int n, float _keep_prob=1, bool _dropout=false, string _layer_type=&quot;Conv2d&quot;, string _act=&quot;None&quot;, int _paddle=2, int f=3, int s=1)</td></tr>
<tr class="separator:ae9b62e715089a55ab0116ffca0273b78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0d901b98eb5021966ae8505fa6f9d10"><td class="memItemLeft" align="right" valign="top"><a id="af0d901b98eb5021966ae8505fa6f9d10"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>initialize</b> (const int &amp;_n, const float &amp;_lambda, const string &amp;_optimizer, const bool &amp;_batch_norm)</td></tr>
<tr class="separator:af0d901b98eb5021966ae8505fa6f9d10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9107f772abb186fef6102875ecbb1044"><td class="memItemLeft" align="right" valign="top"><a id="a9107f772abb186fef6102875ecbb1044"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a9107f772abb186fef6102875ecbb1044">init_dropout_mask</a> ()</td></tr>
<tr class="memdesc:a9107f772abb186fef6102875ecbb1044"><td class="mdescLeft">&#160;</td><td class="mdescRight">allocate dropout mask memory <br /></td></tr>
<tr class="separator:a9107f772abb186fef6102875ecbb1044"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2287f6aa5f104e27662fddef35c4526b"><td class="memItemLeft" align="right" valign="top"><a id="a2287f6aa5f104e27662fddef35c4526b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a2287f6aa5f104e27662fddef35c4526b">init_weights</a> ()</td></tr>
<tr class="memdesc:a2287f6aa5f104e27662fddef35c4526b"><td class="mdescLeft">&#160;</td><td class="mdescRight">allocate weights memory and initialize <br /></td></tr>
<tr class="separator:a2287f6aa5f104e27662fddef35c4526b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56f5bbcd99da0e1080daf31c1d846dc7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a56f5bbcd99da0e1080daf31c1d846dc7">init_momentum_rms</a> ()</td></tr>
<tr class="memdesc:a56f5bbcd99da0e1080daf31c1d846dc7"><td class="mdescLeft">&#160;</td><td class="mdescRight">allocate weights memory and initialize for convnet  <a href="#a56f5bbcd99da0e1080daf31c1d846dc7">More...</a><br /></td></tr>
<tr class="separator:a56f5bbcd99da0e1080daf31c1d846dc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22da044600618c5a18e0ace0c7e82ce4"><td class="memItemLeft" align="right" valign="top"><a id="a22da044600618c5a18e0ace0c7e82ce4"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a22da044600618c5a18e0ace0c7e82ce4">init_batch_norm_weights</a> ()</td></tr>
<tr class="memdesc:a22da044600618c5a18e0ace0c7e82ce4"><td class="mdescLeft">&#160;</td><td class="mdescRight">initialize batch normalization weights <br /></td></tr>
<tr class="separator:a22da044600618c5a18e0ace0c7e82ce4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab95177a167a987fe4f79da6d78007ff8"><td class="memItemLeft" align="right" valign="top"><a id="ab95177a167a987fe4f79da6d78007ff8"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ab95177a167a987fe4f79da6d78007ff8">init_caches</a> (const int &amp;_n_sample, const bool &amp;is_bp)</td></tr>
<tr class="memdesc:ab95177a167a987fe4f79da6d78007ff8"><td class="mdescLeft">&#160;</td><td class="mdescRight">initialize layer caches <br /></td></tr>
<tr class="separator:ab95177a167a987fe4f79da6d78007ff8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a04f2bd1c1a135a287852adc8fbc8a7"><td class="memItemLeft" align="right" valign="top"><a id="a3a04f2bd1c1a135a287852adc8fbc8a7"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a3a04f2bd1c1a135a287852adc8fbc8a7">set_dropout_mask</a> ()</td></tr>
<tr class="memdesc:a3a04f2bd1c1a135a287852adc8fbc8a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">set up dropout mask <br /></td></tr>
<tr class="separator:a3a04f2bd1c1a135a287852adc8fbc8a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa54834f30f3a0a0e080f14eee8671e66"><td class="memItemLeft" align="right" valign="top"><a id="aa54834f30f3a0a0e080f14eee8671e66"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aa54834f30f3a0a0e080f14eee8671e66">clear_caches</a> (const bool &amp;is_bp)</td></tr>
<tr class="memdesc:aa54834f30f3a0a0e080f14eee8671e66"><td class="mdescLeft">&#160;</td><td class="mdescRight">clear layer caches <br /></td></tr>
<tr class="separator:aa54834f30f3a0a0e080f14eee8671e66"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6dfe9e4ff2366b6d9f678da8aed3864"><td class="memItemLeft" align="right" valign="top"><a id="ae6dfe9e4ff2366b6d9f678da8aed3864"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ae6dfe9e4ff2366b6d9f678da8aed3864">print_parameters</a> ()</td></tr>
<tr class="memdesc:ae6dfe9e4ff2366b6d9f678da8aed3864"><td class="mdescLeft">&#160;</td><td class="mdescRight">print layer parameters <br /></td></tr>
<tr class="separator:ae6dfe9e4ff2366b6d9f678da8aed3864"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0749412819158d20143f9491ffd4df0"><td class="memItemLeft" align="right" valign="top"><a id="aa0749412819158d20143f9491ffd4df0"></a>
float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aa0749412819158d20143f9491ffd4df0">getmax</a> (float *x, const int &amp;range)</td></tr>
<tr class="memdesc:aa0749412819158d20143f9491ffd4df0"><td class="mdescLeft">&#160;</td><td class="mdescRight">get the max value given a float vector <br /></td></tr>
<tr class="separator:aa0749412819158d20143f9491ffd4df0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f42e9d07a9105b54b232ecfd401d80c"><td class="memItemLeft" align="right" valign="top"><a id="a1f42e9d07a9105b54b232ecfd401d80c"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>sigmoid_activate</b> ()</td></tr>
<tr class="separator:a1f42e9d07a9105b54b232ecfd401d80c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c637d6b01e43cb3f9b242cf3e0a536f"><td class="memItemLeft" align="right" valign="top"><a id="a7c637d6b01e43cb3f9b242cf3e0a536f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ReLU_activate</b> ()</td></tr>
<tr class="separator:a7c637d6b01e43cb3f9b242cf3e0a536f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6fa54d462cd710aa54317514f06d3b5"><td class="memItemLeft" align="right" valign="top"><a id="ac6fa54d462cd710aa54317514f06d3b5"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>sigmoid_backward</b> ()</td></tr>
<tr class="separator:ac6fa54d462cd710aa54317514f06d3b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a7ecddeef12e7e6c453efe2e5e00ded"><td class="memItemLeft" align="right" valign="top"><a id="a4a7ecddeef12e7e6c453efe2e5e00ded"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>ReLU_backward</b> ()</td></tr>
<tr class="separator:a4a7ecddeef12e7e6c453efe2e5e00ded"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fca70dba1fbfeb4836972abc4704627"><td class="memItemLeft" align="right" valign="top"><a id="a4fca70dba1fbfeb4836972abc4704627"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>get_softmax</b> ()</td></tr>
<tr class="separator:a4fca70dba1fbfeb4836972abc4704627"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5acbeb703238468dc76e96bc775c8f14"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a5acbeb703238468dc76e96bc775c8f14">forward_activated_propagate</a> (const bool &amp;eval)</td></tr>
<tr class="separator:a5acbeb703238468dc76e96bc775c8f14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0de9d8b348299e9e907045cb694ca623"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a0de9d8b348299e9e907045cb694ca623">backward_propagate</a> ()</td></tr>
<tr class="separator:a0de9d8b348299e9e907045cb694ca623"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae9e5f2bbc831769425601d8b89c3566"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aae9e5f2bbc831769425601d8b89c3566">gradient_descent_optimize</a> (const float &amp;initial_learning_rate, const int &amp;num_epochs, const int &amp;step)</td></tr>
<tr class="separator:aae9e5f2bbc831769425601d8b89c3566"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64458fd647b7c3401ae7b84af484894e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a64458fd647b7c3401ae7b84af484894e">Adam_optimize</a> (const float &amp;initial_learning_rate, const float &amp;beta_1, const float &amp;beta_2, const int &amp;num_epochs, const int &amp;epoch_step, const int &amp;train_step)</td></tr>
<tr class="separator:a64458fd647b7c3401ae7b84af484894e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a1aad55761aac2426c0c1c80673b96838"><td class="memItemLeft" align="right" valign="top"><a id="a1aad55761aac2426c0c1c80673b96838"></a>
<a class="el" href="classlayers.html">layers</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>prev</b></td></tr>
<tr class="separator:a1aad55761aac2426c0c1c80673b96838"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab14bf8790f7910c579d48f513458cb08"><td class="memItemLeft" align="right" valign="top"><a id="ab14bf8790f7910c579d48f513458cb08"></a>
<a class="el" href="classlayers.html">layers</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>next</b></td></tr>
<tr class="separator:ab14bf8790f7910c579d48f513458cb08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad04e81230e6fa1b52f0adc1a600a7893"><td class="memItemLeft" align="right" valign="top"><a id="ad04e81230e6fa1b52f0adc1a600a7893"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ad04e81230e6fa1b52f0adc1a600a7893">L</a></td></tr>
<tr class="memdesc:ad04e81230e6fa1b52f0adc1a600a7893"><td class="mdescLeft">&#160;</td><td class="mdescRight">pointer to the previous and next layer <br /></td></tr>
<tr class="separator:ad04e81230e6fa1b52f0adc1a600a7893"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af87e51b897edf5659e850cf990b4b71b"><td class="memItemLeft" align="right" valign="top"><a id="af87e51b897edf5659e850cf990b4b71b"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>area</b></td></tr>
<tr class="separator:af87e51b897edf5659e850cf990b4b71b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c41e30266947dd4efb0e4cf65e08233"><td class="memItemLeft" align="right" valign="top"><a id="a2c41e30266947dd4efb0e4cf65e08233"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>n_channel</b></td></tr>
<tr class="separator:a2c41e30266947dd4efb0e4cf65e08233"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96517a76542c1980ead354935c65bdd8"><td class="memItemLeft" align="right" valign="top"><a id="a96517a76542c1980ead354935c65bdd8"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>dim</b></td></tr>
<tr class="separator:a96517a76542c1980ead354935c65bdd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a551fc66f00bced4735f051f991e6f0e6"><td class="memItemLeft" align="right" valign="top"><a id="a551fc66f00bced4735f051f991e6f0e6"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>n_sample</b></td></tr>
<tr class="separator:a551fc66f00bced4735f051f991e6f0e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea5b2bddc84307320429ef281a4c8e7a"><td class="memItemLeft" align="right" valign="top"><a id="aea5b2bddc84307320429ef281a4c8e7a"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aea5b2bddc84307320429ef281a4c8e7a">dim_W</a></td></tr>
<tr class="memdesc:aea5b2bddc84307320429ef281a4c8e7a"><td class="mdescLeft">&#160;</td><td class="mdescRight">L, area=L*L, dim=area*n_channel,. <br /></td></tr>
<tr class="separator:aea5b2bddc84307320429ef281a4c8e7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24ac26a3f60cbbd6b2f7b00f70265908"><td class="memItemLeft" align="right" valign="top"><a id="a24ac26a3f60cbbd6b2f7b00f70265908"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>dim_b</b></td></tr>
<tr class="separator:a24ac26a3f60cbbd6b2f7b00f70265908"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cc08ea9d8969054b7dd8a1cf9a8f009"><td class="memItemLeft" align="right" valign="top"><a id="a5cc08ea9d8969054b7dd8a1cf9a8f009"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a5cc08ea9d8969054b7dd8a1cf9a8f009">padding</a></td></tr>
<tr class="memdesc:a5cc08ea9d8969054b7dd8a1cf9a8f009"><td class="mdescLeft">&#160;</td><td class="mdescRight">size of W,dW,VdW,SdW, and b,db,Vdb,Sdb <br /></td></tr>
<tr class="separator:a5cc08ea9d8969054b7dd8a1cf9a8f009"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab34eb64067d13b540b08fc1d30221bbb"><td class="memItemLeft" align="right" valign="top"><a id="ab34eb64067d13b540b08fc1d30221bbb"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>stride</b></td></tr>
<tr class="separator:ab34eb64067d13b540b08fc1d30221bbb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9b5849815357ff659054868ba33d3df"><td class="memItemLeft" align="right" valign="top"><a id="ae9b5849815357ff659054868ba33d3df"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>filter_size</b></td></tr>
<tr class="separator:ae9b5849815357ff659054868ba33d3df"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac043b91a40d0bbaa91cd722d8bc5acb6"><td class="memItemLeft" align="right" valign="top"><a id="ac043b91a40d0bbaa91cd722d8bc5acb6"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>filter_area</b></td></tr>
<tr class="separator:ac043b91a40d0bbaa91cd722d8bc5acb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad612451a228f04d1e5479bdae7e695ad"><td class="memItemLeft" align="right" valign="top"><a id="ad612451a228f04d1e5479bdae7e695ad"></a>
string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ad612451a228f04d1e5479bdae7e695ad">layer_type</a></td></tr>
<tr class="memdesc:ad612451a228f04d1e5479bdae7e695ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">parameter for conv nets <br /></td></tr>
<tr class="separator:ad612451a228f04d1e5479bdae7e695ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a880a921dd4143a26832f17c926187b17"><td class="memItemLeft" align="right" valign="top"><a id="a880a921dd4143a26832f17c926187b17"></a>
string&#160;</td><td class="memItemRight" valign="bottom"><b>activation</b></td></tr>
<tr class="separator:a880a921dd4143a26832f17c926187b17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f58b19cadee76f9b0d371a6e22ab46a"><td class="memItemLeft" align="right" valign="top"><a id="a3f58b19cadee76f9b0d371a6e22ab46a"></a>
string&#160;</td><td class="memItemRight" valign="bottom"><b>optimizer</b></td></tr>
<tr class="separator:a3f58b19cadee76f9b0d371a6e22ab46a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab04983c161cd8f7d5341bb6495860c2a"><td class="memItemLeft" align="right" valign="top"><a id="ab04983c161cd8f7d5341bb6495860c2a"></a>
VSLStreamStatePtr&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ab04983c161cd8f7d5341bb6495860c2a">rndStream</a></td></tr>
<tr class="memdesc:ab04983c161cd8f7d5341bb6495860c2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">layer,activation and optimization types <br /></td></tr>
<tr class="separator:ab04983c161cd8f7d5341bb6495860c2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9ef745cd9bca4ed228f050f8551fb5c"><td class="memItemLeft" align="right" valign="top"><a id="aa9ef745cd9bca4ed228f050f8551fb5c"></a>
unsigned&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aa9ef745cd9bca4ed228f050f8551fb5c">weights_seed</a></td></tr>
<tr class="memdesc:aa9ef745cd9bca4ed228f050f8551fb5c"><td class="mdescLeft">&#160;</td><td class="mdescRight">pointer to the mkl random number generator <br /></td></tr>
<tr class="separator:aa9ef745cd9bca4ed228f050f8551fb5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01d61702976f21805852aac69b66fd58"><td class="memItemLeft" align="right" valign="top"><a id="a01d61702976f21805852aac69b66fd58"></a>
unsigned&#160;</td><td class="memItemRight" valign="bottom"><b>mkl_seed</b></td></tr>
<tr class="separator:a01d61702976f21805852aac69b66fd58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace892c775dfd195eb6351ac1224f31f8"><td class="memItemLeft" align="right" valign="top"><a id="ace892c775dfd195eb6351ac1224f31f8"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ace892c775dfd195eb6351ac1224f31f8">dropout</a></td></tr>
<tr class="memdesc:ace892c775dfd195eb6351ac1224f31f8"><td class="mdescLeft">&#160;</td><td class="mdescRight">seed for generate weights and dropout masks <br /></td></tr>
<tr class="separator:ace892c775dfd195eb6351ac1224f31f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7895d2bfac9e1fd5864ea6cd7f995c28"><td class="memItemLeft" align="right" valign="top"><a id="a7895d2bfac9e1fd5864ea6cd7f995c28"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>batch_norm</b></td></tr>
<tr class="separator:a7895d2bfac9e1fd5864ea6cd7f995c28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac33f732bf6e5d9f5504900568f980873"><td class="memItemLeft" align="right" valign="top"><a id="ac33f732bf6e5d9f5504900568f980873"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>is_init</b></td></tr>
<tr class="separator:ac33f732bf6e5d9f5504900568f980873"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02e2636b027b76f2a1ccf91255369667"><td class="memItemLeft" align="right" valign="top"><a id="a02e2636b027b76f2a1ccf91255369667"></a>
float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a02e2636b027b76f2a1ccf91255369667">keep_prob</a></td></tr>
<tr class="memdesc:a02e2636b027b76f2a1ccf91255369667"><td class="mdescLeft">&#160;</td><td class="mdescRight">if dropout is used, if batch_norm is used, if variables are initialized <br /></td></tr>
<tr class="separator:a02e2636b027b76f2a1ccf91255369667"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab377fdf90afdcf7a0f840b6330304720"><td class="memItemLeft" align="right" valign="top"><a id="ab377fdf90afdcf7a0f840b6330304720"></a>
float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#ab377fdf90afdcf7a0f840b6330304720">Lambda</a></td></tr>
<tr class="memdesc:ab377fdf90afdcf7a0f840b6330304720"><td class="mdescLeft">&#160;</td><td class="mdescRight">keep probability <br /></td></tr>
<tr class="separator:ab377fdf90afdcf7a0f840b6330304720"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ce5fe2141ddd9783e3c853fc4fa3a85"><td class="memItemLeft" align="right" valign="top"><a id="a1ce5fe2141ddd9783e3c853fc4fa3a85"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a1ce5fe2141ddd9783e3c853fc4fa3a85">A</a></td></tr>
<tr class="memdesc:a1ce5fe2141ddd9783e3c853fc4fa3a85"><td class="mdescLeft">&#160;</td><td class="mdescRight">L2-regularization parameter. <br /></td></tr>
<tr class="separator:a1ce5fe2141ddd9783e3c853fc4fa3a85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd3b8705806ac66711c9d657d74325f1"><td class="memItemLeft" align="right" valign="top"><a id="acd3b8705806ac66711c9d657d74325f1"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>dropout_mask</b></td></tr>
<tr class="separator:acd3b8705806ac66711c9d657d74325f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a757561eefe890220edabef4f08af7864"><td class="memItemLeft" align="right" valign="top"><a id="a757561eefe890220edabef4f08af7864"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a757561eefe890220edabef4f08af7864">W</a></td></tr>
<tr class="memdesc:a757561eefe890220edabef4f08af7864"><td class="mdescLeft">&#160;</td><td class="mdescRight">layer activation values and dropout mask <br /></td></tr>
<tr class="separator:a757561eefe890220edabef4f08af7864"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42011c939edc7181782d84725b97d375"><td class="memItemLeft" align="right" valign="top"><a id="a42011c939edc7181782d84725b97d375"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>b</b></td></tr>
<tr class="separator:a42011c939edc7181782d84725b97d375"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a315183bd292717ee2c13eaaf5dd3799d"><td class="memItemLeft" align="right" valign="top"><a id="a315183bd292717ee2c13eaaf5dd3799d"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a315183bd292717ee2c13eaaf5dd3799d">dW</a></td></tr>
<tr class="memdesc:a315183bd292717ee2c13eaaf5dd3799d"><td class="mdescLeft">&#160;</td><td class="mdescRight">weights and bias <br /></td></tr>
<tr class="separator:a315183bd292717ee2c13eaaf5dd3799d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77f55acd4d75c66251991669edd183eb"><td class="memItemLeft" align="right" valign="top"><a id="a77f55acd4d75c66251991669edd183eb"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>db</b></td></tr>
<tr class="separator:a77f55acd4d75c66251991669edd183eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e56d96ab4c7b1492e631b952f1a88a6"><td class="memItemLeft" align="right" valign="top"><a id="a2e56d96ab4c7b1492e631b952f1a88a6"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a2e56d96ab4c7b1492e631b952f1a88a6">B</a></td></tr>
<tr class="memdesc:a2e56d96ab4c7b1492e631b952f1a88a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">gradients <br /></td></tr>
<tr class="separator:a2e56d96ab4c7b1492e631b952f1a88a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2b105de0680f4df18e65c003f94e538"><td class="memItemLeft" align="right" valign="top"><a id="af2b105de0680f4df18e65c003f94e538"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>dB</b></td></tr>
<tr class="separator:af2b105de0680f4df18e65c003f94e538"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eb00787fc0cfcaad1d1c906a08144a3"><td class="memItemLeft" align="right" valign="top"><a id="a1eb00787fc0cfcaad1d1c906a08144a3"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>G</b></td></tr>
<tr class="separator:a1eb00787fc0cfcaad1d1c906a08144a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52fce5b8b2d7bb5d4a3c8bb7d881de0d"><td class="memItemLeft" align="right" valign="top"><a id="a52fce5b8b2d7bb5d4a3c8bb7d881de0d"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>dG</b></td></tr>
<tr class="separator:a52fce5b8b2d7bb5d4a3c8bb7d881de0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8ed3e7f362049bacefcda14edc2d2d23"><td class="memItemLeft" align="right" valign="top"><a id="a8ed3e7f362049bacefcda14edc2d2d23"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>dZ</b></td></tr>
<tr class="separator:a8ed3e7f362049bacefcda14edc2d2d23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb0437bb015f962e5b40ee51342e94e8"><td class="memItemLeft" align="right" valign="top"><a id="acb0437bb015f962e5b40ee51342e94e8"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>dA</b></td></tr>
<tr class="separator:acb0437bb015f962e5b40ee51342e94e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64725f364a787b6ca3907ed272a18806"><td class="memItemLeft" align="right" valign="top"><a id="a64725f364a787b6ca3907ed272a18806"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#a64725f364a787b6ca3907ed272a18806">VdW</a></td></tr>
<tr class="memdesc:a64725f364a787b6ca3907ed272a18806"><td class="mdescLeft">&#160;</td><td class="mdescRight">gradients dZ and gradients cache dA <br /></td></tr>
<tr class="separator:a64725f364a787b6ca3907ed272a18806"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9641f18d7b6d94c2b38c031918cdc945"><td class="memItemLeft" align="right" valign="top"><a id="a9641f18d7b6d94c2b38c031918cdc945"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>Vdb</b></td></tr>
<tr class="separator:a9641f18d7b6d94c2b38c031918cdc945"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a452f2a63702004d0e539fc12916112dd"><td class="memItemLeft" align="right" valign="top"><a id="a452f2a63702004d0e539fc12916112dd"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>SdW</b></td></tr>
<tr class="separator:a452f2a63702004d0e539fc12916112dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73600a9c5817cefc696d561bbbf8c3a2"><td class="memItemLeft" align="right" valign="top"><a id="a73600a9c5817cefc696d561bbbf8c3a2"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>Sdb</b></td></tr>
<tr class="separator:a73600a9c5817cefc696d561bbbf8c3a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca1b8f36411394c589df73986408396a"><td class="memItemLeft" align="right" valign="top"><a id="aca1b8f36411394c589df73986408396a"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlayers.html#aca1b8f36411394c589df73986408396a">VdW_corrected</a></td></tr>
<tr class="memdesc:aca1b8f36411394c589df73986408396a"><td class="mdescLeft">&#160;</td><td class="mdescRight">momentum and rms for dW,db used for Adam optimization <br /></td></tr>
<tr class="separator:aca1b8f36411394c589df73986408396a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae090434fa4340ff89121183b7db2fd2a"><td class="memItemLeft" align="right" valign="top"><a id="ae090434fa4340ff89121183b7db2fd2a"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>Vdb_corrected</b></td></tr>
<tr class="separator:ae090434fa4340ff89121183b7db2fd2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace062f0ae964bb8a8ab63b61b72a69c6"><td class="memItemLeft" align="right" valign="top"><a id="ace062f0ae964bb8a8ab63b61b72a69c6"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>SdW_corrected</b></td></tr>
<tr class="separator:ace062f0ae964bb8a8ab63b61b72a69c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad128f94d70f3cb4f280d0af814963522"><td class="memItemLeft" align="right" valign="top"><a id="ad128f94d70f3cb4f280d0af814963522"></a>
float *&#160;</td><td class="memItemRight" valign="bottom"><b>Sdb_corrected</b></td></tr>
<tr class="separator:ad128f94d70f3cb4f280d0af814963522"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a4490dba95a8f233ca7e383fb3b20a822"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4490dba95a8f233ca7e383fb3b20a822">&#9670;&nbsp;</a></span>layers() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">layers::layers </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>d</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>_keep_prob</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>_dropout</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>_layer_type</em> = <code>&quot;None&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>_act</em> = <code>&quot;None&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>constructor </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d</td><td>layer dimension </td></tr>
    <tr><td class="paramname">length</td><td>image length </td></tr>
    <tr><td class="paramname">_keep_prob</td><td>keep_prob </td></tr>
    <tr><td class="paramname">dropout</td><td>if dropout is used </td></tr>
    <tr><td class="paramname">_layer_type</td><td>layer type </td></tr>
    <tr><td class="paramname">_act</td><td>activation type </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae9b62e715089a55ab0116ffca0273b78"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9b62e715089a55ab0116ffca0273b78">&#9670;&nbsp;</a></span>layers() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">layers::layers </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>_keep_prob</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>_dropout</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>_layer_type</em> = <code>&quot;Conv2d&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>_act</em> = <code>&quot;None&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>_paddle</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>f</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>s</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>constructor </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>No. of channels </td></tr>
    <tr><td class="paramname">_keep_prob</td><td>keep_prob </td></tr>
    <tr><td class="paramname">dropout</td><td>if dropout is used </td></tr>
    <tr><td class="paramname">_layer_type</td><td>layer type </td></tr>
    <tr><td class="paramname">_act</td><td>activation type </td></tr>
    <tr><td class="paramname">_paddle</td><td>padding </td></tr>
    <tr><td class="paramname">_f</td><td>filter_size </td></tr>
    <tr><td class="paramname">_s</td><td>stride </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a64458fd647b7c3401ae7b84af484894e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64458fd647b7c3401ae7b84af484894e">&#9670;&nbsp;</a></span>Adam_optimize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void layers::Adam_optimize </td>
          <td>(</td>
          <td class="paramtype">const float &amp;&#160;</td>
          <td class="paramname"><em>initial_learning_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float &amp;&#160;</td>
          <td class="paramname"><em>beta_1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float &amp;&#160;</td>
          <td class="paramname"><em>beta_2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>num_epochs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>epoch_step</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>train_step</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>update all the weights W and bias b with Adam optimizer <br />
 decrease the learning to 1% of the initial learning rate after all the training sets consumed <br />
 learning_rate=initial_learning_rate*(1-step/num_epochs)+0.01*initial_learning_rate <br />
</p>
<p>for each layer <br />
 W:=W-learning_rate*dW <br />
 b:=b-learning_rate*db <br />
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>learning rate </td></tr>
    <tr><td class="paramname">num_epochs</td><td>No. of epochs in the update </td></tr>
    <tr><td class="paramname">epoch_step</td><td>epoch step </td></tr>
    <tr><td class="paramname">train_step</td><td>total train step </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>W,b updated </dd></dl>

</div>
</div>
<a id="a0de9d8b348299e9e907045cb694ca623"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0de9d8b348299e9e907045cb694ca623">&#9670;&nbsp;</a></span>backward_propagate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void layers::backward_propagate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>backward propagate for each layer <br />
 if J is the total mean cost, denote all <br />
 <img class="formulaInl" alt="$\partial{J}/\partial{A}\to dA$" src="form_0.png"/>, <img class="formulaInl" alt="$\partial{J}/\partial{Z}\to dZ$" src="form_1.png"/>, <br />
 <img class="formulaInl" alt="$\partial{J}/\partial{W}\to dW$" src="form_2.png"/>, <img class="formulaInl" alt="$\partial{J}/\partial{b}\to db$" src="form_3.png"/>, <br />
 <img class="formulaInl" alt="$\partial{A}/\partial{Z}\to dF$" src="form_4.png"/> <br />
 and denote layer_dims[l]-&gt;n_[l], * for dot product, .* for element-wise product <br />
 input: dZ,prev-&gt;A,W <br />
</p>
<p>update: <br />
 db(dim)=sum(dZ(n_sample,dim),axis=0) <br />
 dW(dim,prev-&gt;dim)=dZ(n_sample,dim).T*prev-&gt;A(n_sample,prev-&gt;dim) <br />
 dA=activation_backward(prev-&gt;A(n_sample,prev-&gt;n) <br />
 prev-&gt;dZ(n_sample,prev-&gt;dim)=(dZ(n_sample,dim)*W(dim,prev-&gt;dim)).*dA(n_sample,prev-&gt;dim) <br />
</p>
<p>output: prev-&gt;dZ,dW,db <br />
 </p><dl class="section return"><dt>Returns</dt><dd>prev-&gt;dZ,dW,db updated </dd></dl>
<p>dW(n_channel,filter_size,filter_size,prev-&gt;n_channel)=dZ(n_sample,n_channel,L,L)*prev-&gt;A(n_sample,prev-&gt;n_channel,prev-&gt;L,prev-&gt;L)</p>
<p>prev-&gt;dA(n_sample,prev-&gt;n_channel,prev-&gt;L,prev-&gt;L)=dZ(n_sample,n_channel,L,L)*W(n_channel,prev-&gt;n_channel,filter_size,filter_size) </p>

</div>
</div>
<a id="a5acbeb703238468dc76e96bc775c8f14"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5acbeb703238468dc76e96bc775c8f14">&#9670;&nbsp;</a></span>forward_activated_propagate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void layers::forward_activated_propagate </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>eval</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Forward propagate and activation for each layer <br />
 input: prev-&gt;A,W,b,prev-&gt; dropout_mask <br />
</p>
<p>update: <br />
 if prev-&gt;dropout==true: prev-&gt;A=prev-&gt;A.* prev-&gt;dropout_mask <br />
 A=activation_function(W.T* prev-&gt;A+b) <br />
</p>
<p>output: A <br />
 </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">eval</td><td>if eval==true, dropout is not used </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A updated </dd></dl>
<p>Z(n_sample,n_channel,L,L)=W(n_channel,filter_size,filter_size,prev-&gt;n_channel)*prev-&gt;A(n_sample,prev-&gt;n_channel,prev-&gt;L,prev-&gt;L) L=(prev-&gt;L+2*padding-filter_size)/stride+1, sum over (filter_size/stride, filter_size/stride,prev-&gt;n_channel)</p>
<p>Z(n_sample,n_channel,L,L)=max{ prev-&gt;A(n_sample,prev-&gt;n_channel,prev-&gt;L,prev-&gt;L) ,(filter_size,stride)} L=(prev-&gt;L-filter_size)/stride+1, sum over (filter_size,filter_size)/stride, leave n_channel unchanged</p>
<p>max pooling, does not change No. of channels </p>

</div>
</div>
<a id="aae9e5f2bbc831769425601d8b89c3566"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae9e5f2bbc831769425601d8b89c3566">&#9670;&nbsp;</a></span>gradient_descent_optimize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void layers::gradient_descent_optimize </td>
          <td>(</td>
          <td class="paramtype">const float &amp;&#160;</td>
          <td class="paramname"><em>initial_learning_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>num_epochs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>step</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>update all the weights W and bias b with gradient descent <br />
 decrease the learning to 1% of the initial learning rate after all the training sets consumed <br />
 learning_rate=initial_learning_rate*(1-step/num_epochs)+0.01*initial_learning_rate <br />
</p>
<p>for each layer <br />
 W:=W-learning_rate*dW <br />
 b:=b-learning_rate*db <br />
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learning_rate</td><td>learning rate </td></tr>
    <tr><td class="paramname">num_epochs</td><td>No. of epochs in the update </td></tr>
    <tr><td class="paramname">step</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>W,b updated </dd></dl>

</div>
</div>
<a id="a56f5bbcd99da0e1080daf31c1d846dc7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56f5bbcd99da0e1080daf31c1d846dc7">&#9670;&nbsp;</a></span>init_momentum_rms()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void layers::init_momentum_rms </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>allocate weights memory and initialize for convnet </p>
<p>create memory space for Adam optimizer variables </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="layers_8h_source.html">layers.h</a></li>
<li>layers.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
