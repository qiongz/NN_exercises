<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>deep neural network programming exercises: layers.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">deep neural network programming exercises
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">layers.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#ifndef LAYERS_H</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#define LAYERS_H</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include&lt;cstdlib&gt;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include&lt;random&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include&lt;cmath&gt;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include&lt;cstdio&gt;</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include&lt;vector&gt;</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include&lt;iostream&gt;</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include&lt;cstring&gt;</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include&lt;string&gt;</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include&lt;ctime&gt;</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include&quot;mkl.h&quot;</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#define EPSILON 1e-8</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#define METHOD_INT VSL_RNG_METHOD_UNIFORMBITS_STD</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#define METHOD_FLOAT VSL_RNG_METHOD_UNIFORM_STD</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacestd.html">std</a>;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno"><a class="line" href="classlayers.html">   31</a></span>&#160;<span class="keyword">class </span><a class="code" href="classlayers.html">layers</a> {</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00042"></a><span class="lineno"><a class="line" href="classlayers.html#a4490dba95a8f233ca7e383fb3b20a822">   42</a></span>&#160;    <a class="code" href="classlayers.html#a4490dba95a8f233ca7e383fb3b20a822">layers</a>(<span class="keywordtype">int</span> d,<span class="keywordtype">int</span> length,<span class="keywordtype">float</span> _keep_prob=1,<span class="keywordtype">bool</span> _dropout=<span class="keyword">false</span>,<span class="keywordtype">string</span> _layer_type=<span class="stringliteral">&quot;None&quot;</span>,<span class="keywordtype">string</span> _act=<span class="stringliteral">&quot;None&quot;</span>):dim(d),L(length),keep_prob(_keep_prob),dropout(_dropout),layer_type(_layer_type),activation(_act) {</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        area=L*L;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        n_channel=1;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        optimizer=<span class="stringliteral">&quot;sgd&quot;</span>;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        batch_norm=<span class="keyword">false</span>;</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        Lambda=0;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;        is_init=<span class="keyword">false</span>;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;        prev=NULL;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;        next=NULL;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    }</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00064"></a><span class="lineno"><a class="line" href="classlayers.html#ae9b62e715089a55ab0116ffca0273b78">   64</a></span>&#160;    <a class="code" href="classlayers.html#ae9b62e715089a55ab0116ffca0273b78">layers</a>(<span class="keywordtype">int</span> n,<span class="keywordtype">float</span> _keep_prob=1,<span class="keywordtype">bool</span> _dropout=<span class="keyword">false</span>,<span class="keywordtype">string</span> _layer_type=<span class="stringliteral">&quot;Conv2d&quot;</span>,<span class="keywordtype">string</span> _act=<span class="stringliteral">&quot;None&quot;</span>,<span class="keywordtype">int</span> _paddle=2,<span class="keywordtype">int</span> f=3,<span class="keywordtype">int</span> s=1 ):n_channel(n),keep_prob(_keep_prob),dropout(_dropout),layer_type(_layer_type),activation(_act),padding(_paddle),filter_size(f),stride(s) {</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        filter_area=filter_size*filter_size;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;        optimizer=<span class="stringliteral">&quot;sgd&quot;</span>;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;        batch_norm=<span class="keyword">false</span>;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        Lambda=0;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;        is_init=<span class="keyword">false</span>;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        prev=NULL;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;        next=NULL;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    }</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    ~<a class="code" href="classlayers.html">layers</a>();</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    <span class="comment">/***</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">     * Initialize all the layer variables</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">     * @param _n  n_sample</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">     * @param _lambda Lambda</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment">     * @param _optimizer optimizer </span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment">     * @param _batch_norm batch normalization parameter</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">     */</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keywordtype">void</span> initialize(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;_n,<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;_lambda,<span class="keyword">const</span> <span class="keywordtype">string</span> &amp;_optimizer,<span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;_batch_norm);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    <span class="keywordtype">void</span> init_dropout_mask();</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keywordtype">void</span> init_weights();</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    <span class="keywordtype">void</span> init_momentum_rms();</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keywordtype">void</span> init_batch_norm_weights();</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <span class="keywordtype">void</span> init_caches(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;_n_sample,<span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;is_bp);</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    <span class="keywordtype">void</span> set_dropout_mask();</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    <span class="keywordtype">void</span> clear_caches(<span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;is_bp);</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keywordtype">void</span> print_parameters();</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    <span class="keywordtype">float</span> getmax(<span class="keywordtype">float</span> *x,<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;range);</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;   </div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="comment">// activation functions </span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;    <span class="keywordtype">void</span> sigmoid_activate();</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;    <span class="keywordtype">void</span> ReLU_activate();</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    <span class="keywordtype">void</span> sigmoid_backward();</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    <span class="keywordtype">void</span> ReLU_backward();</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    <span class="keywordtype">void</span> get_softmax();</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    <span class="keywordtype">void</span> forward_activated_propagate(<span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;eval);</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    <span class="keywordtype">void</span> backward_propagate();</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    <span class="keywordtype">void</span> gradient_descent_optimize(<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;initial_learning_rate,<span class="keyword">const</span> <span class="keywordtype">int</span> &amp; num_epochs, <span class="keyword">const</span> <span class="keywordtype">int</span> &amp;step);</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;    <span class="keywordtype">void</span> Adam_optimize(<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;initial_learning_rate,<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;beta_1,<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;beta_2,<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;num_epochs,<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;epoch_step,<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;train_step);</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;    <a class="code" href="classlayers.html">layers</a> *prev,*next;   </div><div class="line"><a name="l00180"></a><span class="lineno"><a class="line" href="classlayers.html#ad04e81230e6fa1b52f0adc1a600a7893">  180</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classlayers.html#ad04e81230e6fa1b52f0adc1a600a7893">L</a>,area,n_channel,dim,n_sample;      </div><div class="line"><a name="l00181"></a><span class="lineno"><a class="line" href="classlayers.html#aea5b2bddc84307320429ef281a4c8e7a">  181</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classlayers.html#aea5b2bddc84307320429ef281a4c8e7a">dim_W</a>,dim_b;   </div><div class="line"><a name="l00182"></a><span class="lineno"><a class="line" href="classlayers.html#a5cc08ea9d8969054b7dd8a1cf9a8f009">  182</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classlayers.html#a5cc08ea9d8969054b7dd8a1cf9a8f009">padding</a>,stride,filter_size,filter_area;   </div><div class="line"><a name="l00183"></a><span class="lineno"><a class="line" href="classlayers.html#ad612451a228f04d1e5479bdae7e695ad">  183</a></span>&#160;    <span class="keywordtype">string</span> <a class="code" href="classlayers.html#ad612451a228f04d1e5479bdae7e695ad">layer_type</a>,activation,optimizer;   </div><div class="line"><a name="l00184"></a><span class="lineno"><a class="line" href="classlayers.html#ab04983c161cd8f7d5341bb6495860c2a">  184</a></span>&#160;    VSLStreamStatePtr <a class="code" href="classlayers.html#ab04983c161cd8f7d5341bb6495860c2a">rndStream</a>;      </div><div class="line"><a name="l00185"></a><span class="lineno"><a class="line" href="classlayers.html#aa9ef745cd9bca4ed228f050f8551fb5c">  185</a></span>&#160;    <span class="keywordtype">unsigned</span> <a class="code" href="classlayers.html#aa9ef745cd9bca4ed228f050f8551fb5c">weights_seed</a>,mkl_seed;  </div><div class="line"><a name="l00186"></a><span class="lineno"><a class="line" href="classlayers.html#ace892c775dfd195eb6351ac1224f31f8">  186</a></span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classlayers.html#ace892c775dfd195eb6351ac1224f31f8">dropout</a>,batch_norm,is_init;  </div><div class="line"><a name="l00187"></a><span class="lineno"><a class="line" href="classlayers.html#a02e2636b027b76f2a1ccf91255369667">  187</a></span>&#160;    <span class="keywordtype">float</span> <a class="code" href="classlayers.html#a02e2636b027b76f2a1ccf91255369667">keep_prob</a>;                 </div><div class="line"><a name="l00188"></a><span class="lineno"><a class="line" href="classlayers.html#ab377fdf90afdcf7a0f840b6330304720">  188</a></span>&#160;    <span class="keywordtype">float</span> <a class="code" href="classlayers.html#ab377fdf90afdcf7a0f840b6330304720">Lambda</a>;                </div><div class="line"><a name="l00189"></a><span class="lineno"><a class="line" href="classlayers.html#a1ce5fe2141ddd9783e3c853fc4fa3a85">  189</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#a1ce5fe2141ddd9783e3c853fc4fa3a85">A</a>,*dropout_mask;   </div><div class="line"><a name="l00190"></a><span class="lineno"><a class="line" href="classlayers.html#a757561eefe890220edabef4f08af7864">  190</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#a757561eefe890220edabef4f08af7864">W</a>,*b;    </div><div class="line"><a name="l00191"></a><span class="lineno"><a class="line" href="classlayers.html#a315183bd292717ee2c13eaaf5dd3799d">  191</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#a315183bd292717ee2c13eaaf5dd3799d">dW</a>,*db;  </div><div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="classlayers.html#a2e56d96ab4c7b1492e631b952f1a88a6">  192</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#a2e56d96ab4c7b1492e631b952f1a88a6">B</a>,*dB,*G,*dG; <span class="comment">// batch normalization weights</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    <span class="keywordtype">float</span> *dZ,*dA;   </div><div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="classlayers.html#a64725f364a787b6ca3907ed272a18806">  194</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#a64725f364a787b6ca3907ed272a18806">VdW</a>,*Vdb,*SdW,*Sdb; </div><div class="line"><a name="l00195"></a><span class="lineno"><a class="line" href="classlayers.html#aca1b8f36411394c589df73986408396a">  195</a></span>&#160;    <span class="keywordtype">float</span> *<a class="code" href="classlayers.html#aca1b8f36411394c589df73986408396a">VdW_corrected</a>,*Vdb_corrected,*SdW_corrected,*Sdb_corrected; <span class="comment">// bias corrected momentum and rms for Adam optimization</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;};</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="classlayers_html_a02e2636b027b76f2a1ccf91255369667"><div class="ttname"><a href="classlayers.html#a02e2636b027b76f2a1ccf91255369667">layers::keep_prob</a></div><div class="ttdeci">float keep_prob</div><div class="ttdoc">if dropout is used, if batch_norm is used, if variables are initialized </div><div class="ttdef"><b>Definition:</b> layers.h:187</div></div>
<div class="ttc" id="classlayers_html_a2e56d96ab4c7b1492e631b952f1a88a6"><div class="ttname"><a href="classlayers.html#a2e56d96ab4c7b1492e631b952f1a88a6">layers::B</a></div><div class="ttdeci">float * B</div><div class="ttdoc">gradients </div><div class="ttdef"><b>Definition:</b> layers.h:192</div></div>
<div class="ttc" id="classlayers_html"><div class="ttname"><a href="classlayers.html">layers</a></div><div class="ttdef"><b>Definition:</b> layers.h:31</div></div>
<div class="ttc" id="classlayers_html_ab377fdf90afdcf7a0f840b6330304720"><div class="ttname"><a href="classlayers.html#ab377fdf90afdcf7a0f840b6330304720">layers::Lambda</a></div><div class="ttdeci">float Lambda</div><div class="ttdoc">keep probability </div><div class="ttdef"><b>Definition:</b> layers.h:188</div></div>
<div class="ttc" id="classlayers_html_ace892c775dfd195eb6351ac1224f31f8"><div class="ttname"><a href="classlayers.html#ace892c775dfd195eb6351ac1224f31f8">layers::dropout</a></div><div class="ttdeci">bool dropout</div><div class="ttdoc">seed for generate weights and dropout masks </div><div class="ttdef"><b>Definition:</b> layers.h:186</div></div>
<div class="ttc" id="classlayers_html_aca1b8f36411394c589df73986408396a"><div class="ttname"><a href="classlayers.html#aca1b8f36411394c589df73986408396a">layers::VdW_corrected</a></div><div class="ttdeci">float * VdW_corrected</div><div class="ttdoc">momentum and rms for dW,db used for Adam optimization </div><div class="ttdef"><b>Definition:</b> layers.h:195</div></div>
<div class="ttc" id="namespacestd_html"><div class="ttname"><a href="namespacestd.html">std</a></div></div>
<div class="ttc" id="classlayers_html_a64725f364a787b6ca3907ed272a18806"><div class="ttname"><a href="classlayers.html#a64725f364a787b6ca3907ed272a18806">layers::VdW</a></div><div class="ttdeci">float * VdW</div><div class="ttdoc">gradients dZ and gradients cache dA </div><div class="ttdef"><b>Definition:</b> layers.h:194</div></div>
<div class="ttc" id="classlayers_html_a4490dba95a8f233ca7e383fb3b20a822"><div class="ttname"><a href="classlayers.html#a4490dba95a8f233ca7e383fb3b20a822">layers::layers</a></div><div class="ttdeci">layers(int d, int length, float _keep_prob=1, bool _dropout=false, string _layer_type=&quot;None&quot;, string _act=&quot;None&quot;)</div><div class="ttdef"><b>Definition:</b> layers.h:42</div></div>
<div class="ttc" id="classlayers_html_ab04983c161cd8f7d5341bb6495860c2a"><div class="ttname"><a href="classlayers.html#ab04983c161cd8f7d5341bb6495860c2a">layers::rndStream</a></div><div class="ttdeci">VSLStreamStatePtr rndStream</div><div class="ttdoc">layer,activation and optimization types </div><div class="ttdef"><b>Definition:</b> layers.h:184</div></div>
<div class="ttc" id="classlayers_html_aa9ef745cd9bca4ed228f050f8551fb5c"><div class="ttname"><a href="classlayers.html#aa9ef745cd9bca4ed228f050f8551fb5c">layers::weights_seed</a></div><div class="ttdeci">unsigned weights_seed</div><div class="ttdoc">pointer to the mkl random number generator </div><div class="ttdef"><b>Definition:</b> layers.h:185</div></div>
<div class="ttc" id="classlayers_html_a5cc08ea9d8969054b7dd8a1cf9a8f009"><div class="ttname"><a href="classlayers.html#a5cc08ea9d8969054b7dd8a1cf9a8f009">layers::padding</a></div><div class="ttdeci">int padding</div><div class="ttdoc">size of W,dW,VdW,SdW, and b,db,Vdb,Sdb </div><div class="ttdef"><b>Definition:</b> layers.h:182</div></div>
<div class="ttc" id="classlayers_html_ad04e81230e6fa1b52f0adc1a600a7893"><div class="ttname"><a href="classlayers.html#ad04e81230e6fa1b52f0adc1a600a7893">layers::L</a></div><div class="ttdeci">int L</div><div class="ttdoc">pointer to the previous and next layer </div><div class="ttdef"><b>Definition:</b> layers.h:180</div></div>
<div class="ttc" id="classlayers_html_ad612451a228f04d1e5479bdae7e695ad"><div class="ttname"><a href="classlayers.html#ad612451a228f04d1e5479bdae7e695ad">layers::layer_type</a></div><div class="ttdeci">string layer_type</div><div class="ttdoc">parameter for conv nets </div><div class="ttdef"><b>Definition:</b> layers.h:183</div></div>
<div class="ttc" id="classlayers_html_a1ce5fe2141ddd9783e3c853fc4fa3a85"><div class="ttname"><a href="classlayers.html#a1ce5fe2141ddd9783e3c853fc4fa3a85">layers::A</a></div><div class="ttdeci">float * A</div><div class="ttdoc">L2-regularization parameter. </div><div class="ttdef"><b>Definition:</b> layers.h:189</div></div>
<div class="ttc" id="classlayers_html_ae9b62e715089a55ab0116ffca0273b78"><div class="ttname"><a href="classlayers.html#ae9b62e715089a55ab0116ffca0273b78">layers::layers</a></div><div class="ttdeci">layers(int n, float _keep_prob=1, bool _dropout=false, string _layer_type=&quot;Conv2d&quot;, string _act=&quot;None&quot;, int _paddle=2, int f=3, int s=1)</div><div class="ttdef"><b>Definition:</b> layers.h:64</div></div>
<div class="ttc" id="classlayers_html_a315183bd292717ee2c13eaaf5dd3799d"><div class="ttname"><a href="classlayers.html#a315183bd292717ee2c13eaaf5dd3799d">layers::dW</a></div><div class="ttdeci">float * dW</div><div class="ttdoc">weights and bias </div><div class="ttdef"><b>Definition:</b> layers.h:191</div></div>
<div class="ttc" id="classlayers_html_a757561eefe890220edabef4f08af7864"><div class="ttname"><a href="classlayers.html#a757561eefe890220edabef4f08af7864">layers::W</a></div><div class="ttdeci">float * W</div><div class="ttdoc">layer activation values and dropout mask </div><div class="ttdef"><b>Definition:</b> layers.h:190</div></div>
<div class="ttc" id="classlayers_html_aea5b2bddc84307320429ef281a4c8e7a"><div class="ttname"><a href="classlayers.html#aea5b2bddc84307320429ef281a4c8e7a">layers::dim_W</a></div><div class="ttdeci">int dim_W</div><div class="ttdoc">L, area=L*L, dim=area*n_channel,. </div><div class="ttdef"><b>Definition:</b> layers.h:181</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
